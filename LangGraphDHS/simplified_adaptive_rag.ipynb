{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "907798c6",
   "metadata": {},
   "source": [
    "## Simplified Adaptive RAG Example: Wikipedia Data (India Economy & AI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a85424",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a5c023",
   "metadata": {},
   "source": [
    "### Load Data from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2beb401",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "urls = [\n",
    "    \"https://en.wikipedia.org/wiki/Economy_of_India\",\n",
    "    \"https://en.wikipedia.org/wiki/Artificial_intelligence\"\n",
    "]\n",
    "\n",
    "loaders = [WebBaseLoader(url) for url in urls]\n",
    "docs = [loader.load() for loader in loaders]\n",
    "doc_list = [item for sublist in docs for item in sublist]\n",
    "len(doc_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d11593e",
   "metadata": {},
   "source": [
    "### Split & Store in Vector Database (FAISS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26132e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=800, chunk_overlap=100\n",
    ")\n",
    "doc_split = text_splitter.split_documents(doc_list)\n",
    "\n",
    "vectorstore = FAISS.from_documents(doc_split, OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e791a0",
   "metadata": {},
   "source": [
    "### Router (Decide whether to use Vectorstore or fallback to Web Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaf9d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "class RouteQuery(BaseModel):\n",
    "    datasource: Literal[\"vectorstore\", \"web_search\"] = Field(\n",
    "        description=\"Choose 'vectorstore' if the answer is likely in Wikipedia docs, otherwise 'web_search'.\"\n",
    "    )\n",
    "\n",
    "llm_router = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "structured_router = llm_router.with_structured_output(RouteQuery)\n",
    "\n",
    "structured_router.invoke({\"input\": \"What is the GDP of India?\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2975d302",
   "metadata": {},
   "source": [
    "### Retrieval Grader (Check if retrieved docs are relevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cdd61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GradeDocuments(BaseModel):\n",
    "    binary_score: str = Field(description=\"Relevant to the question? yes or no\")\n",
    "\n",
    "llm_grader = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "structured_grader = llm_grader.with_structured_output(GradeDocuments)\n",
    "\n",
    "retrieved_docs = retriever.invoke(\"What is the GDP of India?\")\n",
    "structured_grader.invoke({\"question\": \"What is the GDP of India?\", \"documents\": str(retrieved_docs)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5ceaed",
   "metadata": {},
   "source": [
    "### Generate Final Answer with RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bf0d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "question = \"What is the GDP of India?\"\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "docs = retriever.invoke(question)\n",
    "answer = rag_chain.invoke({\"context\": format_docs(docs), \"question\": question})\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f2a8a1",
   "metadata": {},
   "source": [
    "### Try Another Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1073c34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "question2 = \"How is Artificial Intelligence impacting jobs?\"\n",
    "\n",
    "docs2 = retriever.invoke(question2)\n",
    "answer2 = rag_chain.invoke({\"context\": format_docs(docs2), \"question\": question2})\n",
    "print(answer2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
